{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved RAG System for A Christmas Carol\n",
    "\n",
    "This notebook implements an **improved** RAG (Retrieval-Augmented Generation) system with the following enhancements:\n",
    "\n",
    "## Key Improvements:\n",
    "\n",
    "1. **Skip Reformulation** - Search directly with original question (simpler, faster)\n",
    "2. **Increased Context** - Retrieve 5-10 chunks instead of 3\n",
    "3. **Better Chunking** - Use 512 character overlap (was 50) for better context preservation\n",
    "4. **Persistent Storage** - Use ChromaDB PersistentClient to avoid re-embedding\n",
    "5. **Improved Prompt** - Add instructions for handling \"unknown\" cases\n",
    "6. **Larger Model** - Use FLAN-T5-large (780M params vs 250M)\n",
    "7. **Reranking** - Add cross-encoder reranking for better relevance\n",
    "8. **Source Attribution** - Show chunk IDs and metadata with answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from langchain_community.document_loaders import UnstructuredEPubLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "import chromadb\n",
    "from uuid import uuid4\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement #3: Better Chunking Strategy\n",
    "\n",
    "**Changed from:**\n",
    "- chunk_size = 1024\n",
    "- chunk_overlap = 50 (only 5%!)\n",
    "\n",
    "**Changed to:**\n",
    "- chunk_size = 1024 (same)\n",
    "- chunk_overlap = 512 (50% overlap)\n",
    "\n",
    "**Why this matters:**\n",
    "- 512 character overlap ensures important context at chunk boundaries is preserved\n",
    "- Prevents conversations/paragraphs from being split awkwardly\n",
    "- Each chunk shares significant context with neighbors\n",
    "- Improves retrieval quality when answer spans multiple chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load document with improved chunking\n",
    "chunk_size = 1024\n",
    "chunk_overlap = 512  # IMPROVED: 50% overlap instead of 5%\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, \n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "epub_loader = UnstructuredEPubLoader('./docs/charles-dickens_a-christmas-carol.epub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not load translations for en-US\n",
      "  data file translations/en.yaml not found\n",
      "[WARNING] The term Abstract has no translation defined.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 274\n",
      "\n",
      "Sample chunk:\n",
      "page_content='\u201cMy time grows short,\u201d observed the Spirit. \u201cQuick!\u201d\n",
      "\n",
      "This was not addressed to Scrooge, or to anyone whom he could see, but it produced an immediate effect. For again Scrooge saw himself. He was older now; a man in the prime of life. His face had not the harsh and rigid lines of later years; but it had begun to wear the signs of care and avarice. There was an eager, greedy, restless motion in the eye, which showed the passion that had taken root, and where the shadow of the growing tree would fall.\n",
      "\n",
      "He was not alone, but sat by the side of a fair young girl in a mourning dress: in whose eyes there were tears, which sparkled in the light that shone out of the Ghost of Christmas Past.\n",
      "\n",
      "\u201cIt matters little,\u201d she said softly. \u201cTo you, very little. Another idol has displaced me; and, if it can cheer and comfort you in time to come as I would have tried to do, I have no just cause to grieve.\u201d\n",
      "\n",
      "\u201cWhat idol has displaced you?\u201d he rejoined.\n",
      "\n",
      "\u201cA golden one.\u201d' metadata={'source': './docs/charles-dickens_a-christmas-carol.epub'}\n"
     ]
    }
   ],
   "source": [
    "# Split document\n",
    "chunks = epub_loader.load_and_split(text_splitter)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"\\nSample chunk:\\n{chunks[100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding model (same as before - works well)\n",
    "embed_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "chroma_embed_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement #4: Persistent ChromaDB Storage\n",
    "\n",
    "**Changed from:**\n",
    "```python\n",
    "ch_client = chromadb.Client()  # Ephemeral - lost on restart\n",
    "```\n",
    "\n",
    "**Changed to:**\n",
    "```python\n",
    "ch_client = chromadb.PersistentClient(path=\"./chroma_db\")  # Saved to disk\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- No need to re-embed documents every time\n",
    "- Much faster startup after first run\n",
    "- Production-ready storage\n",
    "- Can share database across multiple sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts: 274\n",
      "Total IDs: 274\n",
      "Sample metadata: {'chunk_id': 0, 'source': './docs/charles-dickens_a-christmas-carol.epub', 'text_preview': 'Imprint\\n\\nThe Standard Ebooks logo.\\n\\nThis ebook is the product of many hours of hard work by voluntee...'}\n"
     ]
    }
   ],
   "source": [
    "# Prepare chunks for ChromaDB\n",
    "texts = [c.page_content for c in chunks]\n",
    "text_ids = [str(uuid4())[:8] for _ in range(len(texts))]\n",
    "\n",
    "# Store chunk metadata for source attribution (Improvement #8)\n",
    "metadatas = [\n",
    "    {\n",
    "        \"chunk_id\": i,\n",
    "        \"source\": chunks[i].metadata.get(\"source\", \"unknown\"),\n",
    "        \"text_preview\": texts[i][:100] + \"...\"\n",
    "    }\n",
    "    for i in range(len(texts))\n",
    "]\n",
    "\n",
    "print(f\"Total texts: {len(texts)}\")\n",
    "print(f\"Total IDs: {len(text_ids)}\")\n",
    "print(f\"Sample metadata: {metadatas[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection: carol_improved\n",
      "Created collection: carol_improved\n"
     ]
    }
   ],
   "source": [
    "# IMPROVEMENT #4: Create PERSISTENT Chroma client\n",
    "col_name = 'carol_improved'\n",
    "\n",
    "ch_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Drop existing collection if it exists\n",
    "try:\n",
    "    ch_client.delete_collection(col_name)\n",
    "    print(f\"Deleted existing collection: {col_name}\")\n",
    "except:\n",
    "    print(f\"No existing collection to delete\")\n",
    "\n",
    "# Create collection with metadata\n",
    "carol_col = ch_client.create_collection(\n",
    "    name=col_name,\n",
    "    embedding_function=chroma_embed_func,\n",
    "    metadata={\"description\": \"A Christmas Carol with improved chunking and metadata\"}\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {col_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection contains 274 documents\n"
     ]
    }
   ],
   "source": [
    "# Insert documents with metadata\n",
    "carol_col.add(\n",
    "    documents=texts,\n",
    "    ids=text_ids,\n",
    "    metadatas=metadatas  # IMPROVEMENT #8: Store metadata for source attribution\n",
    ")\n",
    "\n",
    "print(f\"Collection contains {carol_col.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Basic Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What happened to Marley?\n",
      "\n",
      "Top 5 results:\n",
      "\n",
      "1. ID: e6eb8a19, Distance: 0.2571\n",
      "   Preview: Their faithful Friend and Servant,\n",
      "\n",
      "C. D.\n",
      "\n",
      "December, 1843.\n",
      "\n",
      "Stave I\n",
      "\n",
      "Marley\u2019s Ghost\n",
      "\n",
      "Marley was dead, to begin with. There is no doubt whatever about ...\n",
      "\n",
      "2. ID: 6bca2ca7, Distance: 0.3132\n",
      "   Preview: Scrooge had often heard it said that Marley had no bowels, but he had never believed it until now.\n",
      "\n",
      "No, nor did he believe it even now. Though he look...\n",
      "\n",
      "3. ID: 43eb3f5b, Distance: 0.3197\n",
      "   Preview: \u201cIt\u2019s humbug still!\u201d said Scrooge. \u201cI won\u2019t believe it.\u201d\n",
      "\n",
      "His colour changed, though, when, without a pause, it came on through the heavy door and pas...\n",
      "\n",
      "4. ID: e2b05587, Distance: 0.3263\n",
      "   Preview: Mind! I don\u2019t mean to say that I know of my own knowledge, what there is particularly dead about a doornail. I might have been inclined, myself, to re...\n",
      "\n",
      "5. ID: 3686ea7c, Distance: 0.3268\n",
      "   Preview: Standard Ebooks is a volunteer-driven project that produces ebook editions of public domain literature using modern typography, technology, and editor...\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "query = \"What happened to Marley?\"\n",
    "\n",
    "results = carol_col.query(\n",
    "    query_texts=[query],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nTop 5 results:\")\n",
    "for i, (doc_id, distance, doc) in enumerate(zip(\n",
    "    results['ids'][0], \n",
    "    results['distances'][0], \n",
    "    results['documents'][0]\n",
    ")):\n",
    "    print(f\"\\n{i+1}. ID: {doc_id}, Distance: {distance:.4f}\")\n",
    "    print(f\"   Preview: {doc[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement #6: Use Larger Model (FLAN-T5-Large)\n",
    "\n",
    "**Changed from:**\n",
    "- google/flan-t5-base (250M parameters)\n",
    "\n",
    "**Changed to:**\n",
    "- google/flan-t5-large (780M parameters)\n",
    "\n",
    "**Benefits:**\n",
    "- Better reasoning capabilities\n",
    "- More accurate answers\n",
    "- Better instruction following\n",
    "- Can handle longer contexts\n",
    "\n",
    "**Note:** If this is too slow/large, you can also try:\n",
    "- google/flan-t5-xl (3B parameters) for even better quality\n",
    "- Or keep flan-t5-base if speed is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d6c1a5cf1e48f2a236e8d0a94d73f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bde6e43eaf4e1495557cae7405ac50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c5d50d381f41e18e392da7c7a7f766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39c13325a904c578be6a2037e3bee46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474afca905c9420cb1cd1fcae4d33d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec278d46f40f483bb522fc974e549de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5006d76865144e7b7555b7e494f8eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: google/flan-t5-large\n",
      "Model parameters: 783M\n"
     ]
    }
   ],
   "source": [
    "# IMPROVEMENT #6: Load larger model\n",
    "model_name = \"google/flan-t5-large\"  # Was: flan-t5-base\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Loaded model: {model_name}\")\n",
    "print(f\"Model parameters: {model.num_parameters() / 1e6:.0f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement #7: Add Reranking with Cross-Encoder\n",
    "\n",
    "**What is reranking?**\n",
    "- Initial retrieval uses bi-encoder (fast but less accurate)\n",
    "- Reranking uses cross-encoder (slower but more accurate)\n",
    "- Cross-encoder sees query + document together, not separately\n",
    "- Better at determining relevance\n",
    "\n",
    "**Process:**\n",
    "1. Retrieve top-K chunks (e.g., 10) with bi-encoder\n",
    "2. Rerank with cross-encoder\n",
    "3. Use top-N reranked chunks (e.g., 5) for answer generation\n",
    "\n",
    "**Model used:** `cross-encoder/ms-marco-MiniLM-L-6-v2`\n",
    "- Fast and effective\n",
    "- Trained on MS MARCO passage ranking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a5db67a3e94ec5ac47cf928196a876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7caf7d31c64139a0018b778bca2bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158c279624fa44fca5b3569d32a6d6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc836b3bf4848258074ccee223c40f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6460ab50af474ffd9b6df73195607c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb996338a5041349c682a8ae3acae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded reranker: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    }
   ],
   "source": [
    "# IMPROVEMENT #7: Load cross-encoder for reranking\n",
    "reranker_model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(reranker_model_name)\n",
    "reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model_name)\n",
    "\n",
    "print(f\"Loaded reranker: {reranker_model_name}\")\n",
    "\n",
    "def rerank_results(query, documents, top_k=5):\n",
    "    \"\"\"\n",
    "    Rerank documents using cross-encoder.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        documents: List of document texts\n",
    "        top_k: Number of top results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (score, doc_index) tuples, sorted by score descending\n",
    "    \"\"\"\n",
    "    # Create query-document pairs\n",
    "    pairs = [[query, doc] for doc in documents]\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = reranker_tokenizer(\n",
    "        pairs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Get scores\n",
    "    with torch.no_grad():\n",
    "        scores = reranker_model(**inputs).logits.squeeze(-1)\n",
    "    \n",
    "    # Sort by score\n",
    "    scored_docs = [(score.item(), i) for i, score in enumerate(scores)]\n",
    "    scored_docs.sort(reverse=True, key=lambda x: x[0])\n",
    "    \n",
    "    return scored_docs[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete RAG Pipeline with All Improvements\n",
    "\n",
    "### Changes from Original:\n",
    "\n",
    "1. **No reformulation step** - Search directly with question\n",
    "2. **Retrieve 10 chunks** - More context candidates\n",
    "3. **Rerank to top 5** - Better relevance selection\n",
    "4. **Improved prompt** - Instructions for unknown cases\n",
    "5. **Source attribution** - Return chunk IDs and previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_improved(question, retrieve_k=10, use_k=5, show_sources=True):\n",
    "    \"\"\"\n",
    "    Improved RAG pipeline.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        retrieve_k: Number of chunks to retrieve initially (default: 10)\n",
    "        use_k: Number of chunks to use after reranking (default: 5)\n",
    "        show_sources: Whether to show source chunks (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'answer', 'sources', and 'confidence'\n",
    "    \"\"\"\n",
    "    \n",
    "    # IMPROVEMENT #1: Skip reformulation, search with original question\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    # IMPROVEMENT #2: Retrieve more chunks (10 instead of 3)\n",
    "    print(f\"Retrieving top {retrieve_k} chunks...\")\n",
    "    results = carol_col.query(\n",
    "        query_texts=[question],\n",
    "        n_results=retrieve_k,\n",
    "        include=['documents', 'metadatas', 'distances']\n",
    "    )\n",
    "    \n",
    "    documents = results['documents'][0]\n",
    "    metadatas = results['metadatas'][0]\n",
    "    doc_ids = results['ids'][0]\n",
    "    initial_distances = results['distances'][0]\n",
    "    \n",
    "    # IMPROVEMENT #7: Rerank with cross-encoder\n",
    "    print(f\"Reranking with cross-encoder...\")\n",
    "    reranked = rerank_results(question, documents, top_k=use_k)\n",
    "    \n",
    "    # Get top reranked documents\n",
    "    top_docs = [documents[idx] for score, idx in reranked]\n",
    "    top_metadatas = [metadatas[idx] for score, idx in reranked]\n",
    "    top_ids = [doc_ids[idx] for score, idx in reranked]\n",
    "    top_scores = [score for score, idx in reranked]\n",
    "    \n",
    "    # Combine context from top reranked chunks\n",
    "    context = \"\\n\\n---\\n\\n\".join(top_docs)\n",
    "    \n",
    "    # IMPROVEMENT #5: Better prompt - put question first to avoid truncation issues\n",
    "    # Using a simpler, more direct prompt format that works better with FLAN-T5\n",
    "    question_prompt = f\"\"\"Answer the following question based on the context provided.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Generate answer\n",
    "    print(f\"Generating answer with {model_name}...\\n\")\n",
    "    enc_prompt = tokenizer(\n",
    "        question_prompt, \n",
    "        return_tensors='pt',\n",
    "        max_length=1024,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    enc_answer = model.generate(\n",
    "        enc_prompt.input_ids,\n",
    "        max_length=100,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    answer = tokenizer.decode(enc_answer[0], skip_special_tokens=True)\n",
    "    \n",
    "    # IMPROVEMENT #8: Show sources with chunk IDs\n",
    "    sources = []\n",
    "    if show_sources:\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ANSWER: {answer}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nSOURCES (Top {use_k} chunks after reranking):\\n\")\n",
    "        \n",
    "        for i, (doc_id, metadata, score, doc) in enumerate(zip(\n",
    "            top_ids, top_metadatas, top_scores, top_docs\n",
    "        )):\n",
    "            source_info = {\n",
    "                'chunk_id': metadata['chunk_id'],\n",
    "                'doc_id': doc_id,\n",
    "                'rerank_score': score,\n",
    "                'text_preview': doc[:200] + \"...\"\n",
    "            }\n",
    "            sources.append(source_info)\n",
    "            \n",
    "            print(f\"{i+1}. Chunk #{metadata['chunk_id']} (ID: {doc_id})\")\n",
    "            print(f\"   Rerank Score: {score:.4f}\")\n",
    "            print(f\"   Preview: {doc[:150]}...\")\n",
    "            print()\n",
    "    \n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'sources': sources,\n",
    "        'num_chunks_retrieved': retrieve_k,\n",
    "        'num_chunks_used': use_k\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Improved System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the name of Bob Cratchit's youngest son who is ill?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Be concise and specific\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #235 (ID: 850e1a95)\n",
      "   Rerank Score: -1.8312\n",
      "   Preview: \u201cNever, father!\u201d cried they all.\n",
      "\n",
      "\u201cAnd I know,\u201d said Bob, \u201cI know, my dears, that when we recollect how patient and how mild he was; although he was a...\n",
      "\n",
      "2. Chunk #230 (ID: 9e7c7abd)\n",
      "   Rerank Score: -2.0635\n",
      "   Preview: She hurried out to meet him; and little Bob in his comforter\ufeff\u2014he had need of it, poor fellow\ufeff\u2014came in. His tea was ready for him on the hob, and they ...\n",
      "\n",
      "3. Chunk #236 (ID: 72d1b038)\n",
      "   Rerank Score: -2.4814\n",
      "   Preview: \u201cNo, never, father!\u201d they all cried again.\n",
      "\n",
      "\u201cI am very happy,\u201d said little Bob, \u201cI am very happy!\u201d\n",
      "\n",
      "Mrs. Cratchit kissed him, his daughters kissed him...\n",
      "\n",
      "4. Chunk #142 (ID: e54e0bf8)\n",
      "   Rerank Score: -2.7188\n",
      "   Preview: \u201cWe\u2019d a deal of work to finish up last night,\u201d replied the girl, \u201cand had to clear away this morning, mother!\u201d\n",
      "\n",
      "\u201cWell! never mind so long as you are c...\n",
      "\n",
      "5. Chunk #144 (ID: baae210f)\n",
      "   Rerank Score: -3.2993\n",
      "   Preview: Martha didn\u2019t like to see him disappointed, if it were only in joke; so she came out prematurely from behind the closet door, and ran into his arms, w...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test question 1: Simple factual\n",
    "result = answer_question_improved(\n",
    "    \"What is the name of Bob Cratchit's youngest son who is ill?\",\n",
    "    retrieve_k=10,\n",
    "    use_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was Scrooge's deceased business partner?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: I don't have enough information to answer the question.\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #18 (ID: 54a8ebd7)\n",
      "   Rerank Score: 3.1445\n",
      "   Preview: This lunatic, in letting Scrooge\u2019s nephew out, had let two other people in. They were portly gentlemen, pleasant to behold, and now stood, with their ...\n",
      "\n",
      "2. Chunk #3 (ID: e2b05587)\n",
      "   Rerank Score: 3.0446\n",
      "   Preview: Mind! I don\u2019t mean to say that I know of my own knowledge, what there is particularly dead about a doornail. I might have been inclined, myself, to re...\n",
      "\n",
      "3. Chunk #19 (ID: f002351e)\n",
      "   Rerank Score: 2.9361\n",
      "   Preview: \u201cMr. Marley has been dead these seven years,\u201d Scrooge replied. \u201cHe died seven years ago, this very night.\u201d\n",
      "\n",
      "\u201cWe have no doubt his liberality is well r...\n",
      "\n",
      "4. Chunk #198 (ID: 299ed78d)\n",
      "   Rerank Score: -0.0877\n",
      "   Preview: The Spirit stopped beside one little knot of business men. Observing that the hand was pointed to them, Scrooge advanced to listen to their talk.\n",
      "\n",
      "\u201cNo...\n",
      "\n",
      "5. Chunk #202 (ID: cf7b65e9)\n",
      "   Rerank Score: -0.3041\n",
      "   Preview: \u201cNo, no. Something else to think of. Good morning!\u201d\n",
      "\n",
      "Not another word. That was their meeting, their conversation, and their parting.\n",
      "\n",
      "Scrooge was at ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test question 2: Requires inference\n",
    "result = answer_question_improved(\n",
    "    \"Who was Scrooge's deceased business partner?\",\n",
    "    retrieve_k=10,\n",
    "    use_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was Scrooge engaged to in his youth, and why did she leave him?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Be concise and specific\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 7 chunks after reranking):\n",
      "\n",
      "1. Chunk #75 (ID: 753bc4dd)\n",
      "   Rerank Score: -0.1868\n",
      "   Preview: \u201cThese are but shadows of the things that have been,\u201d said the Ghost. \u201cThey have no consciousness of us.\u201d\n",
      "\n",
      "The jocund travellers came on; and as they ...\n",
      "\n",
      "2. Chunk #97 (ID: dd0fb5a4)\n",
      "   Rerank Score: -0.2189\n",
      "   Preview: When the clock struck eleven, this domestic ball broke up. Mr. and Mrs. Fezziwig took their stations, one on either side the door, and, shaking hands ...\n",
      "\n",
      "3. Chunk #112 (ID: 2e96149c)\n",
      "   Rerank Score: -0.2488\n",
      "   Preview: And now Scrooge looked on more attentively than ever, when the master of the house, having his daughter leaning fondly on him, sat down with her and h...\n",
      "\n",
      "4. Chunk #15 (ID: 46f949e5)\n",
      "   Rerank Score: -0.4558\n",
      "   Preview: \u201cBut why?\u201d cried Scrooge\u2019s nephew. \u201cWhy?\u201d\n",
      "\n",
      "\u201cWhy did you get married?\u201d said Scrooge.\n",
      "\n",
      "\u201cBecause I fell in love.\u201d\n",
      "\n",
      "\u201cBecause you fell in love!\u201d growled Sc...\n",
      "\n",
      "5. Chunk #88 (ID: c7225ed6)\n",
      "   Rerank Score: -0.8509\n",
      "   Preview: \u201cAlways a delicate creature, whom a breath might have withered,\u201d said the Ghost. \u201cBut she had a large heart!\u201d\n",
      "\n",
      "\u201cSo she had,\u201d cried Scrooge. \u201cYou\u2019re ri...\n",
      "\n",
      "6. Chunk #100 (ID: 45deecb0)\n",
      "   Rerank Score: -1.0315\n",
      "   Preview: \u201cMy time grows short,\u201d observed the Spirit. \u201cQuick!\u201d\n",
      "\n",
      "This was not addressed to Scrooge, or to anyone whom he could see, but it produced an immediate ...\n",
      "\n",
      "7. Chunk #187 (ID: 1e59f144)\n",
      "   Rerank Score: -1.2426\n",
      "   Preview: Much they saw, and far they went, and many homes they visited, but always with a happy end. The Spirit stood beside sickbeds, and they were cheerful; ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test question 3: Multiple parts\n",
    "result = answer_question_improved(\n",
    "    \"Who was Scrooge engaged to in his youth, and why did she leave him?\",\n",
    "    retrieve_k=10,\n",
    "    use_k=7  # Use more chunks for complex questions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Scrooge's favorite color?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: I don't have enough information to answer the question.\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #124 (ID: dcfa51bf)\n",
      "   Rerank Score: -0.5076\n",
      "   Preview: Scrooge entered timidly, and hung his head before this Spirit. He was not the dogged Scrooge he had been; and though the Spirit\u2019s eyes were clear and ...\n",
      "\n",
      "2. Chunk #39 (ID: 43eb3f5b)\n",
      "   Rerank Score: -1.0077\n",
      "   Preview: \u201cIt\u2019s humbug still!\u201d said Scrooge. \u201cI won\u2019t believe it.\u201d\n",
      "\n",
      "His colour changed, though, when, without a pause, it came on through the heavy door and pas...\n",
      "\n",
      "3. Chunk #126 (ID: ec5f8721)\n",
      "   Rerank Score: -2.9501\n",
      "   Preview: \u201cA tremendous family to provide for,\u201d muttered Scrooge.\n",
      "\n",
      "The Ghost of Christmas Present rose.\n",
      "\n",
      "\u201cSpirit,\u201d said Scrooge submissively, \u201cconduct me where ...\n",
      "\n",
      "4. Chunk #249 (ID: 992848c9)\n",
      "   Rerank Score: -3.7638\n",
      "   Preview: Running to the window, he opened it, and put out his head. No fog, no mist; clear, bright, jovial, stirring, cold; cold, piping for the blood to dance...\n",
      "\n",
      "5. Chunk #170 (ID: e8ea7190)\n",
      "   Rerank Score: -4.1418\n",
      "   Preview: \u201cHa, ha! Ha, ha, ha, ha!\u201d\n",
      "\n",
      "\u201cHe said that Christmas was a humbug, as I live!\u201d cried Scrooge\u2019s nephew. \u201cHe believed it, too!\u201d\n",
      "\n",
      "\u201cMore shame for him, Fred...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test question 4: Testing \"unknown\" handling\n",
    "result = answer_question_improved(\n",
    "    \"What is Scrooge's favorite color?\",  # Not in the book\n",
    "    retrieve_k=10,\n",
    "    use_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Process Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all questions...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Question 1/7\n",
      "================================================================================\n",
      "Question: What is the name of Scrooge's underpaid clerk?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Only answer if the information is clearly stated in the context.\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #9 (ID: 1692abf5)\n",
      "   Rerank Score: 0.7962\n",
      "   Preview: The door of Scrooge\u2019s counting house was open, that he might keep his eye upon his clerk, who in a dismal little cell beyond, a sort of tank, was copy...\n",
      "\n",
      "2. Chunk #28 (ID: 03f5311b)\n",
      "   Rerank Score: 0.2324\n",
      "   Preview: The clerk smiled faintly.\n",
      "\n",
      "\u201cAnd yet,\u201d said Scrooge, \u201cyou don\u2019t think me ill used when I pay a day\u2019s wages for no work.\u201d\n",
      "\n",
      "The clerk observed that it wa...\n",
      "\n",
      "3. Chunk #16 (ID: ab95cb00)\n",
      "   Rerank Score: -2.8719\n",
      "   Preview: \u201cGood afternoon,\u201d said Scrooge.\n",
      "\n",
      "\u201cI want nothing from you; I ask nothing of you; why cannot we be friends?\u201d\n",
      "\n",
      "\u201cGood afternoon!\u201d said Scrooge.\n",
      "\n",
      "\u201cI am so...\n",
      "\n",
      "4. Chunk #258 (ID: 2d3fc6f3)\n",
      "   Rerank Score: -3.1397\n",
      "   Preview: \u201cMr. Scrooge?\u201d\n",
      "\n",
      "\u201cYes,\u201d said Scrooge. \u201cThat is my name, and I fear it may not be pleasant to you. Allow me to ask your pardon. And will you have the go...\n",
      "\n",
      "5. Chunk #171 (ID: 6400d747)\n",
      "   Rerank Score: -4.4370\n",
      "   Preview: \u201cHe\u2019s a comical old fellow,\u201d said Scrooge\u2019s nephew, \u201cthat\u2019s the truth; and not so pleasant as he might be. However, his offences carry their own punis...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Question 2/7\n",
      "================================================================================\n",
      "Question: Who was Scrooge's deceased business partner?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: I don't have enough information to answer the question.\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #18 (ID: 54a8ebd7)\n",
      "   Rerank Score: 3.1445\n",
      "   Preview: This lunatic, in letting Scrooge\u2019s nephew out, had let two other people in. They were portly gentlemen, pleasant to behold, and now stood, with their ...\n",
      "\n",
      "2. Chunk #3 (ID: e2b05587)\n",
      "   Rerank Score: 3.0446\n",
      "   Preview: Mind! I don\u2019t mean to say that I know of my own knowledge, what there is particularly dead about a doornail. I might have been inclined, myself, to re...\n",
      "\n",
      "3. Chunk #19 (ID: f002351e)\n",
      "   Rerank Score: 2.9361\n",
      "   Preview: \u201cMr. Marley has been dead these seven years,\u201d Scrooge replied. \u201cHe died seven years ago, this very night.\u201d\n",
      "\n",
      "\u201cWe have no doubt his liberality is well r...\n",
      "\n",
      "4. Chunk #198 (ID: 299ed78d)\n",
      "   Rerank Score: -0.0877\n",
      "   Preview: The Spirit stopped beside one little knot of business men. Observing that the hand was pointed to them, Scrooge advanced to listen to their talk.\n",
      "\n",
      "\u201cNo...\n",
      "\n",
      "5. Chunk #202 (ID: cf7b65e9)\n",
      "   Rerank Score: -0.3041\n",
      "   Preview: \u201cNo, no. Something else to think of. Good morning!\u201d\n",
      "\n",
      "Not another word. That was their meeting, their conversation, and their parting.\n",
      "\n",
      "Scrooge was at ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Question 3/7\n",
      "================================================================================\n",
      "Question: Who was Scrooge engaged to in his youth, and why did she leave him?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Be concise and specific\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #75 (ID: 753bc4dd)\n",
      "   Rerank Score: -0.1868\n",
      "   Preview: \u201cThese are but shadows of the things that have been,\u201d said the Ghost. \u201cThey have no consciousness of us.\u201d\n",
      "\n",
      "The jocund travellers came on; and as they ...\n",
      "\n",
      "2. Chunk #97 (ID: dd0fb5a4)\n",
      "   Rerank Score: -0.2189\n",
      "   Preview: When the clock struck eleven, this domestic ball broke up. Mr. and Mrs. Fezziwig took their stations, one on either side the door, and, shaking hands ...\n",
      "\n",
      "3. Chunk #112 (ID: 2e96149c)\n",
      "   Rerank Score: -0.2488\n",
      "   Preview: And now Scrooge looked on more attentively than ever, when the master of the house, having his daughter leaning fondly on him, sat down with her and h...\n",
      "\n",
      "4. Chunk #15 (ID: 46f949e5)\n",
      "   Rerank Score: -0.4558\n",
      "   Preview: \u201cBut why?\u201d cried Scrooge\u2019s nephew. \u201cWhy?\u201d\n",
      "\n",
      "\u201cWhy did you get married?\u201d said Scrooge.\n",
      "\n",
      "\u201cBecause I fell in love.\u201d\n",
      "\n",
      "\u201cBecause you fell in love!\u201d growled Sc...\n",
      "\n",
      "5. Chunk #88 (ID: c7225ed6)\n",
      "   Rerank Score: -0.8509\n",
      "   Preview: \u201cAlways a delicate creature, whom a breath might have withered,\u201d said the Ghost. \u201cBut she had a large heart!\u201d\n",
      "\n",
      "\u201cSo she had,\u201d cried Scrooge. \u201cYou\u2019re ri...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Question 4/7\n",
      "================================================================================\n",
      "Question: What is the name of Bob Cratchit's youngest son who is ill?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Be concise and specific\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #235 (ID: 850e1a95)\n",
      "   Rerank Score: -1.8312\n",
      "   Preview: \u201cNever, father!\u201d cried they all.\n",
      "\n",
      "\u201cAnd I know,\u201d said Bob, \u201cI know, my dears, that when we recollect how patient and how mild he was; although he was a...\n",
      "\n",
      "2. Chunk #230 (ID: 9e7c7abd)\n",
      "   Rerank Score: -2.0635\n",
      "   Preview: She hurried out to meet him; and little Bob in his comforter\ufeff\u2014he had need of it, poor fellow\ufeff\u2014came in. His tea was ready for him on the hob, and they ...\n",
      "\n",
      "3. Chunk #236 (ID: 72d1b038)\n",
      "   Rerank Score: -2.4814\n",
      "   Preview: \u201cNo, never, father!\u201d they all cried again.\n",
      "\n",
      "\u201cI am very happy,\u201d said little Bob, \u201cI am very happy!\u201d\n",
      "\n",
      "Mrs. Cratchit kissed him, his daughters kissed him...\n",
      "\n",
      "4. Chunk #142 (ID: e54e0bf8)\n",
      "   Rerank Score: -2.7188\n",
      "   Preview: \u201cWe\u2019d a deal of work to finish up last night,\u201d replied the girl, \u201cand had to clear away this morning, mother!\u201d\n",
      "\n",
      "\u201cWell! never mind so long as you are c...\n",
      "\n",
      "5. Chunk #144 (ID: baae210f)\n",
      "   Rerank Score: -3.2993\n",
      "   Preview: Martha didn\u2019t like to see him disappointed, if it were only in joke; so she came out prematurely from behind the closet door, and ran into his arms, w...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Question 5/7\n",
      "================================================================================\n",
      "Question: What does Scrooge see written on the gravestone that frightens him into changing his ways?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Use information directly from the context\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #240 (ID: 00761e6e)\n",
      "   Rerank Score: 3.2744\n",
      "   Preview: \u201cBefore I draw nearer to that stone to which you point,\u201d said Scrooge, \u201canswer me one question. Are these the shadows of the things that Will be, or a...\n",
      "\n",
      "2. Chunk #241 (ID: 307f1c67)\n",
      "   Rerank Score: 1.9229\n",
      "   Preview: The Spirit was immovable as ever.\n",
      "\n",
      "Scrooge crept towards it, trembling as he went; and, following the finger, read upon the stone of the neglected gra...\n",
      "\n",
      "3. Chunk #195 (ID: b186d8ec)\n",
      "   Rerank Score: 0.7823\n",
      "   Preview: The upper portion of the garment was contracted for an instant in its folds, as if the Spirit had inclined its head. That was the only answer he recei...\n",
      "\n",
      "4. Chunk #45 (ID: 670f9471)\n",
      "   Rerank Score: 0.4947\n",
      "   Preview: At this the spirit raised a frightful cry, and shook its chain with such a dismal and appalling noise, that Scrooge held on tight to his chair, to sav...\n",
      "\n",
      "5. Chunk #220 (ID: 94089630)\n",
      "   Rerank Score: 0.3802\n",
      "   Preview: Scrooge glanced towards the Phantom. Its steady hand was pointed to the head. The cover was so carelessly adjusted that the slightest raising of it, t...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Question 6/7\n",
      "================================================================================\n",
      "Question: What is Scrooge's response when his nephew Fred invites him to Christmas dinner at the beginning of the story?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: I don't have enough information to answer the question.\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #185 (ID: 8ba31ad8)\n",
      "   Rerank Score: 4.4074\n",
      "   Preview: \u201cHe has given us plenty of merriment, I am sure,\u201d said Fred, \u201cand it would be ungrateful not to drink his health. Here is a glass of mulled wine ready...\n",
      "\n",
      "2. Chunk #10 (ID: 6ff77000)\n",
      "   Rerank Score: 3.5314\n",
      "   Preview: \u201cA merry Christmas, uncle! God save you!\u201d cried a cheerful voice. It was the voice of Scrooge\u2019s nephew, who came upon him so quickly that this was the...\n",
      "\n",
      "3. Chunk #12 (ID: bfab18f5)\n",
      "   Rerank Score: 3.1639\n",
      "   Preview: \u201cUncle!\u201d pleaded the nephew.\n",
      "\n",
      "\u201cNephew!\u201d returned the uncle sternly, \u201ckeep Christmas in your own way, and let me keep it in mine.\u201d\n",
      "\n",
      "\u201cKeep it!\u201d repeated...\n",
      "\n",
      "4. Chunk #263 (ID: f4b25739)\n",
      "   Rerank Score: 2.7773\n",
      "   Preview: \u201cWhy, bless my soul!\u201d cried Fred, \u201cwho\u2019s that?\u201d\n",
      "\n",
      "\u201cIt\u2019s I. Your uncle Scrooge. I have come to dinner. Will you let me in, Fred?\u201d\n",
      "\n",
      "Let him in! It is a m...\n",
      "\n",
      "5. Chunk #11 (ID: 90b21ccd)\n",
      "   Rerank Score: 2.5579\n",
      "   Preview: \u201cCome, then,\u201d returned the nephew gaily. \u201cWhat right have you to be dismal? What reason have you to be morose? You\u2019re rich enough.\u201d\n",
      "\n",
      "Scrooge, having n...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Question 7/7\n",
      "================================================================================\n",
      "Question: What specific, generous act does Scrooge perform for the Cratchit family on Christmas morning?\n",
      "\n",
      "Retrieving top 10 chunks...\n",
      "Reranking with cross-encoder...\n",
      "Generating answer with google/flan-t5-large...\n",
      "\n",
      "================================================================================\n",
      "ANSWER: Be concise and specific\n",
      "================================================================================\n",
      "\n",
      "SOURCES (Top 5 chunks after reranking):\n",
      "\n",
      "1. Chunk #138 (ID: 3890fa06)\n",
      "   Rerank Score: 2.1946\n",
      "   Preview: And perhaps it was the pleasure the good Spirit had in showing off this power of his, or else it was his own kind, generous, hearty nature, and his sy...\n",
      "\n",
      "2. Chunk #126 (ID: ec5f8721)\n",
      "   Rerank Score: 1.5385\n",
      "   Preview: \u201cA tremendous family to provide for,\u201d muttered Scrooge.\n",
      "\n",
      "The Ghost of Christmas Present rose.\n",
      "\n",
      "\u201cSpirit,\u201d said Scrooge submissively, \u201cconduct me where ...\n",
      "\n",
      "3. Chunk #157 (ID: d0065fec)\n",
      "   Rerank Score: 0.4144\n",
      "   Preview: \u201cIt should be Christmas Day, I am sure,\u201d said she, \u201con which one drinks the health of such an odious, stingy, hard, unfeeling man as Mr. Scrooge. You ...\n",
      "\n",
      "4. Chunk #156 (ID: db522fa5)\n",
      "   Rerank Score: 0.1400\n",
      "   Preview: Scrooge bent before the Ghost\u2019s rebuke, and, trembling, cast his eyes upon the ground. But he raised them speedily on hearing his own name.\n",
      "\n",
      "\u201cMr. Scro...\n",
      "\n",
      "5. Chunk #236 (ID: 72d1b038)\n",
      "   Rerank Score: -0.2730\n",
      "   Preview: \u201cNo, never, father!\u201d they all cried again.\n",
      "\n",
      "\u201cI am very happy,\u201d said little Bob, \u201cI am very happy!\u201d\n",
      "\n",
      "Mrs. Cratchit kissed him, his daughters kissed him...\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load questions from file if available\n",
    "questions = [\n",
    "    \"What is the name of Scrooge's underpaid clerk?\",\n",
    "    \"Who was Scrooge's deceased business partner?\",\n",
    "    \"Who was Scrooge engaged to in his youth, and why did she leave him?\",\n",
    "    \"What is the name of Bob Cratchit's youngest son who is ill?\",\n",
    "    \"What does Scrooge see written on the gravestone that frightens him into changing his ways?\",\n",
    "    \"What is Scrooge's response when his nephew Fred invites him to Christmas dinner at the beginning of the story?\",\n",
    "    \"What specific, generous act does Scrooge perform for the Cratchit family on Christmas morning?\"\n",
    "]\n",
    "\n",
    "print(\"Processing all questions...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, q in enumerate(questions, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Question {i}/{len(questions)}\")\n",
    "    print(\"=\"*80)\n",
    "    result = answer_question_improved(q, retrieve_k=10, use_k=5, show_sources=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Improvements\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| Aspect | Original | Improved | Impact |\n",
    "|--------|----------|----------|--------|\n",
    "| Chunking overlap | 50 chars (5%) | 512 chars (50%) | Better context preservation |\n",
    "| Storage | Ephemeral (lost on restart) | Persistent (saved to disk) | No re-embedding needed |\n",
    "| Retrieval | 3 chunks | 10 chunks \u2192 reranked to 5 | More comprehensive context |\n",
    "| Question processing | 2-step reformulation | Direct search | Simpler, faster, more accurate |\n",
    "| Model size | FLAN-T5-base (250M) | FLAN-T5-large (780M) | Better reasoning |\n",
    "| Reranking | None | Cross-encoder | Better relevance scoring |\n",
    "| Prompt quality | Basic | Instructive with unknown handling | Better answers |\n",
    "| Source attribution | None | Chunk IDs + metadata | Verifiable answers |\n",
    "\n",
    "### Expected Results\n",
    "\n",
    "The improved system should:\n",
    "- Give more accurate answers\n",
    "- Handle complex multi-part questions better\n",
    "- Correctly identify when information is not available\n",
    "- Provide source citations for verification\n",
    "- Run faster after first initialization (persistent storage)\n",
    "- Be more production-ready\n",
    "\n",
    "### Further Improvements (Optional)\n",
    "\n",
    "If you want to go even further:\n",
    "1. Use a modern LLM (Claude, GPT-4, Llama) instead of FLAN-T5\n",
    "2. Add query expansion (generate multiple query variations)\n",
    "3. Implement hybrid search (keyword + semantic)\n",
    "4. Add semantic chunking (split on topics, not characters)\n",
    "5. Use a better embedding model (e.g., OpenAI ada-002, Cohere embed-v3)\n",
    "6. Add metadata filtering (by chapter, character, etc.)\n",
    "7. Implement multi-hop reasoning for complex questions\n",
    "8. Add answer validation/verification step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ellm-2025-nov17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}